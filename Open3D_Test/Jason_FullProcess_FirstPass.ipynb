{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#33FF9E\">\n",
    "\n",
    "# **First pass to map 3D feature data to 2D radar reference**\n",
    "</span>\n",
    "\n",
    "- First draft: July 09, 2023\n",
    "- revised: July 11, 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Method & Step-by-step Instructions**\n",
    "Prerequisites: LiDAR point cloud data, radar image\n",
    "1. obtain 3D mesh from LiDAR radar image, using MeshLab\n",
    "2. (very importantâ€“code will not run without this!*) fix this mesh, using Blender\n",
    "- remove loose geometry (tiny bits of geometry that are detatched from the terrain of interest; these can be trees or rooftops)\n",
    "- (the most important) run 3D-printing checks in Blender, remove 'non-flat faces'\n",
    "3. obtain 3D feature data ('crest lines'), using CrestCODE\n",
    "- convert 3D mesh to pseudo-PLY2 file format \n",
    "- collect the 'ravines.txt' output from CrestCODE\n",
    "4. obtain flattened mesh from 3D feature data, using Blender & SEA\n",
    "- a flattened mesh is a 3D mesh where the z component of coordinates is set to 0 for all vertices\n",
    "- obtain handles in the form (vertex index, target coordinates) in Blender. 'Vertex index' is the index of the vertex in the mesh file; 'target coordinates' is where we want the indexed vertex to be, in order to match the radar image\n",
    "- run ARAP using handles, collect the resulting deformed mesh\n",
    "- convert the deformed mesh and handles into a JSON file\n",
    "- collect the flattened mesh from SEA\n",
    "5. transfer 3D features into the flattened mesh\n",
    "6. You're done!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Further explanation for step 2**\n",
    "'Non-flat faces' result in optimization failure for both CrestCODE and SEA (the code will not run)\n",
    "- These non-flat faces need to be removed (remove their vertices as well to be safe)\n",
    "- MeshLab functions fail to identify these (unclear why)\n",
    "- In Blender, it takes less than 2 seconds to detect, select, and delete them\n",
    "\n",
    "With non-flat faces removed, the mesh can have very tiny holes that does not affect feature detection\n",
    "- The mesh used for this analysis, with non-flat faces removed\n",
    "<td style=\"width: 480px;\"><img src=\"../Open3D_Test/fixed mesh.png\"/></td>\n",
    "\n",
    "- The non-flat faces, scaled up more than 100 times\n",
    "    - These faces appear to proper triangles, but one of their edges are extremely short compared to any ordinaty triangle in the mesh; this may have caused numerical errors\n",
    "<td style=\"width: 480px;\"><img src=\"../Open3D_Test/non-flat faces.png\"/></td>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Results**\n",
    "Viewing down (orthogonal z direction), 3D features that are transferred to the flattened mesh now more closely match their presumd counterparts on the radar reference, compared to the original 3D features\n",
    "- the ideal time (no mistakes made) for the entire process is 30~40 minutes\n",
    "- prior to gathering handles, the radar reference is rotated and scaled to roughly match the 3D features as much as possible\n",
    "- handles are gathered in two ways (I use 'match' and 'overlap with' interchangeably here)\n",
    "    - for 3D features that already match well with radar reference, handles are used to maintain this correspondence: target coordinates are set to be equal to the original coordinates of the indexed vertices\n",
    "    - for 3D features that do not match with radar reference, handles are used to identify where in the 3D space these 3D features are supposed to be, if they were to match their counterparts on the radar reference\n",
    "\n",
    "<span style=\"color:#33FF9E\">\n",
    "3D features (green lines)\n",
    "</span>\n",
    "against 3D mesh, below\n",
    "<td style=\"width: 480px;\"><img src=\"../Open3D_Test/3d_lines_on_mesh.png\"/></td>\n",
    "\n",
    "<span style=\"color:#de34eb\">\n",
    "2D features (purple lines)\n",
    "</span>\n",
    "against 3D mesh, below\n",
    "<td style=\"width: 480px;\"><img src=\"../Open3D_Test/2d_lines_on_mesh.png\"/></td>\n",
    "\n",
    "<span style=\"color:#33FF9E\">\n",
    "3D features (green lines)\n",
    "</span>\n",
    "against radar reference, below\n",
    "<td style=\"width: 480px;\"><img src=\"../Open3D_Test/3d_lines.png\"/></td>\n",
    "\n",
    "<span style=\"color:#de34eb\">\n",
    "2D features (purple lines)\n",
    "</span>\n",
    "against radar reference, below\n",
    "<td style=\"width: 480px;\"><img src=\"../Open3D_Test/2d_lines.png\"/></td>\n",
    "\n",
    "<span style=\"color:#33FF9E\">\n",
    "3D features (green lines)\n",
    "</span>\n",
    "vs\n",
    "<span style=\"color:#de34eb\">\n",
    "2D features (purple lines)\n",
    "</span>\n",
    "against radar reference, below\n",
    "<td style=\"width: 480px;\"><img src=\"../Open3D_Test/2d_vs_3d.png\"/></td>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Thoughts and Next Steps**\n",
    "1. lack of complete correspondence between 3D features and radar reference\n",
    "- radar reference suggest arcaehological remains that 3D features doesn't (they could be buried too deep and not show up on the surface)\n",
    "    - more insights could come from viewing the radar reference from differnet depths (displayed above is a compilation of radar references from multiple depths)\n",
    "- similarly, 3D features indicate areas of interest that are blank on the radar reference (they could be too recent to be detected by radar)\n",
    "    - to address this issue, a different level of detail could be used to increase the amount of details 3D features capture\n",
    "2. (my) need for more archaeological expertise in evaluating the correspondence between 2D features and radar reference, when they are present"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
