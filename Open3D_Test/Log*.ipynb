{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log\n",
    "This files records progress I made in this project!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friday February 17, 2023\n",
    "Did\n",
    "1. \n",
    ">Additional analysis to areas 5~11"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday February 20, 2023\n",
    "Did\n",
    "1. Mesh analysis\n",
    ">1. Analyzed Enlarged versions for Areas 6, 8, and 11.\n",
    ">2. Reconstructed mesh from point cloud, with varied 'Reconstruction Depth' values from 8 to 5\n",
    ">3. <br>Added curvature colorization (APSS, K1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday March 20, 2023\n",
    "Items I worked on\n",
    "1. GroundTruth_Blender.ipynb\n",
    ">Completed sections: Motivation and Process, Obtaining Ground Truth based on Human Visual Recognition in Blender, \n",
    "><br>Started section: Observations, Drawing Feature Lines in Blender\n",
    "2. Comparison_230310.ipynb\n",
    ">Fixed image display errors\n",
    "3. Drawing_Feature_Lines_Blender.ipynb\n",
    ">Started\n",
    "\n",
    "ALSO: Reorganized folders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday March 21, 2023\n",
    "Did\n",
    "1. Submitted application to Undergraduate Research Symposium\n",
    ">Project title: Feature Extraction from LiDAR Data\n",
    "\n",
    "Items I worked on\n",
    "1. Cropping.blend\n",
    ">obtained shaded images of crop_remote_230314 (tugunbulak)\n",
    "2. GroundTruth_Blender.ipynb\n",
    ">updated image showing my hand-drawn feature lines on the shaded mesh from 1.\n",
    "><br>added observations from comparing hand-drawn feature lines against calculated feature lines and shaded mesh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friday March 24, 2023\n",
    "Did\n",
    "1. Met with Professor Ju to report progress and discuss ideas\n",
    ">Analyzed and evaluated hand-drawn fearture lines from GroundTruth_Blender.ipynb\n",
    "><br>I need to zoom in more to the mesh to delineate smaller features\n",
    "><br>Tasks:\n",
    ">1. Redo hand-drawn feature lines.\n",
    ">2. Work with Professor Frachetti to evaluate my hand-drawn feature lines.\n",
    "><br>&emsp;Learn how to identify and evaluate features\n",
    ">3. Get familiarized with CrestCODE code base\n",
    "><br>&emsp;Possible edits on the base code to introduce additional parameters\n",
    ">4. Try out exaggerated shading tool to investigate features I might miss from the 3D view\n",
    "\n",
    "Items I worked on\n",
    "1. Drawing_Feature_Lines_Blender.ipynb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday March 27, 2023\n",
    "Did\n",
    "1. GroundTruth_Blender.ipynb\n",
    ">Drew updated feature lines!\n",
    "><br>I examined the mesh more closely and drew updated feature lines!\n",
    "><br>I found that Blender's clay_muddy.exr option for MATCAP shows a lot more details other options missed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday March 28, 2023\n",
    "Did\n",
    "1. Met with Professor Frachetti and Jack to discuss the features lines I drew manually\n",
    ">Professor Frachetti reviewed my hand-drawn lines\n",
    ">1. lines drawn by me are not very useful as ground truth\n",
    "><br>&emsp;I do not have expertise, so I miss many features an archaeologist pick up\n",
    "><br>&emsp;Archaeologists can make good conclusions about what an incomplete feature might be. I cannot do that without expertise\n",
    "2. Examined ground truth data we have\n",
    ">There are two sites: Tashbulak (TBK) and Tugunbulak (TGB)\n",
    "><br>both sites have radar data. However, only TBK's image quality (at the time of the meeting) is good for direct comparison against feature lines\n",
    "><br>TBK radar data shows underground walls that form a grid-like pattern.\n",
    "><br>&emsp;They are most likely rooms (that share walls)\n",
    "><br>&emsp;From mesh reconstruction, we identifies large squares in TGB that are not obvious in in-person excavations\n",
    "><br>&emsp;We also have a correspondence between those rooms and grid-like patterns visible on the surface\n",
    "3. Tasks:\n",
    ">I will crop out a small chunk of TBK for which rada data is available.\n",
    ">1. Reconstruct mesh at high accuracy level\n",
    ">2. Colorize the mesh by curvature\n",
    ">3. Generate feature lines\n",
    ">4. Analyze radar data\n",
    "><br>&emsp;The radar data works similar to MRI. At different depths, we get cross-sections of the landscape, in which high-density materials such as walls are indicated in darker colors. \n",
    "><br>&emsp;This means that one certain height, some walls show up and some does not\n",
    "><br>&emsp;For analysis, we overlay these cross-sections so we can see all walls at once\n",
    ">5. Georeference the radar data and the TBK mesh, so that we can accurately overlay them and compare\n",
    "><br>&emsp;At the moment, we can use contour-like roads along the hillside (they show up very clearly in the reconstructed mesh) for alignment\n",
    "4. TBK_FeatureLines_230314.ipynb\n",
    ">Organized and recorded results from Tuesday March 14, 2023\n",
    "5. TBK_GroundTruth_Radar.ipynb\n",
    ">Started\n",
    "><nr>Exported TBK radar data as PNG image\n",
    "6. Reconstructed mesh with **Higher** definition from TBK and TGB point clouds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday March 29, 2023\n",
    "Did\n",
    "1. Met with Professor Ju to discuss next steps for mesh analysis\n",
    ">1. I reported what we learned from meeting on Tuesday March 28, 2023\n",
    ">2. We analyzed the radar ground truth from TBK_GroundTruth_Radar.ipynb\n",
    ">3. Tasks:\n",
    ">>1. Crop out 2 small regions containing many features of interest\n",
    ">>2. Generate feature lines for them\n",
    ">>3. Compaure feature lines against radar ground truth\n",
    "2. Analyzed TBK mesh\n",
    ">1. I cropped the mesh at many differnet decreasing sizes in Meshlab\n",
    "><br>But, the mesh has lots of vertices due to increased definition (depth = 12)\n",
    "><br>So it takes 10~20 minutes to generate feature lines and to run AnalysisPackage_v1.ipynb\n",
    ">>I discovered that I need to use the 'delete faces and vertices option' to remove vertices connected to the faces I select to delete \n",
    "><br>If I don't, the number of vertices do not decrease when I crop the mesh!\n",
    ">\n",
    ">Using this correct method, I cropped out two small regions:\n",
    ">>1. tbk_crop_230328_depth=12_correctNormals_crop_1\n",
    ">>2. tbk_crop_230328_depth=12_correctNormals_crop_2\n",
    ">2. Generated feature lines for crop_1 and crop_2\n",
    ">Setting: k = 6\n",
    "><br>I saved these results as 3D view in .html files\n",
    "><br>Due to high mesh resolution, k = 6 takes about 10 minutes to run per crop!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday March 30, 2023\n",
    "Did:\n",
    "1. generated curvature colorization for tbk_crop_230328_depth=12_correctNormals_crop_1 and tbk_crop_230328_depth=12_correctNormals_crop_2\n",
    ">Settings: MLS Scale = 12, K1\n",
    "2. investigated sharing mesh view option (with feature lines) on GitHub through .html files\n",
    ">It doesn't work\n",
    "2. Comparison_230330.ipynb\n",
    ">Documented mesh analysis results from March 29 and 30 (feature lines and curvature colorization)\n",
    "><br>This time, I annotated a larger area of the mesh (from which the smaller crops were taken) to identify where the two crops come from"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friday March 31, 2023\n",
    "Did:\n",
    "1. developed way to export feature lines as .PLY file\n",
    ">File: AnalysisPackage_v1.ipynb\n",
    "><br>Lines are read in from feature lines .txt output\n",
    "><br>Then, they are processed and output-ed by Open3D's LineSet object!\n",
    "2. Manually aligned TBK's radar image with mesh\n",
    ">File: 230331_ManualAlign\n",
    "><br>I relied on contour-like structures along the hillside\n",
    "><br>The problem is, size of exported radar image does not match size of the mesh\n",
    "><br>(I believe size of mesh is accurate, since it came from LiDAR)\n",
    "3. Analyzed the usefulness of feature lines using radar data as ground truth\n",
    ">File: Comparison_230330*.ipynb\n",
    ">We should georeference the radar data so that we can align it against our mesh (and therefore feature lines) accurately\n",
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday April 3, 2023\n",
    "Did:\n",
    "1. Discussed with Professor Shidal about configuring CrestCODE files for the CLion IDE on my local machine. \n",
    ">CrestCODE comes with a Makefile, but CLion asks for CMakeList.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday April 4, 2023\n",
    "Did:\n",
    "1. Tested generating feature lines at k = 7, 8, 9\n",
    ">File: Comparison_230330.ipynb\n",
    "><br>k = 8 and k = 9 did not work because, I left the computer on to run for more than two hours, and the code did not finish running.\n",
    "2. Modified file naming to include all settings used for feature line generation\n",
    ">File: AnalysisPackage_v1.ipynb\n",
    "3. Analyzed k = 7 feature lines against TBK's radar image (manually aligned on Friday March 31, 2023)\n",
    ">File: Comparison_230330.ipynb\n",
    "\n",
    "Observations\n",
    "1. We need higher k values for cleaner (less noisy) feature lines. But on my laptop, doing so takes too long.\n",
    ">Right now each crop contains two to three room complexes\n",
    "><br>I can probably reduce the run time by taking even smaller crops (one room complex per crop)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday April 5, 2023\n",
    "Did:\n",
    "1. Met with Professor Ju to discuss ways to make feature lines more useful\n",
    ">We considered three approaches:\n",
    ">1. Improving geometry-based methods\n",
    ">>We can modify the CrestCODE code to analyze geometry in a more effective way. We can develop a method to ignore tiny bumps (noise) and only draw feature lines for large/distinct (useful) features\n",
    ">2. Improving analysis of feature lines\n",
    ">>We can find a way to filter noise (short, spaced-out feature lines for tiny bumps on the ground–which are not actual features)\n",
    ">3. Alternative methods\n",
    ">>We discussed the idea of using shading to recognize features. Professor Ju suggested the 'view dependent' method from *apparent ridges* paper. I will look into it!\n",
    ">\n",
    ">We discussed our next step and how it fits in the project as a whole\n",
    ">1. We will focus on extracting features recognizable by human eye\n",
    ">>More can be done to make the feature line outputs cleaner (less noisy)\n",
    ">2. Using results from 1., we will incorporate human evaluation (archaeological expertise) as a filter\n",
    ">>The human eye can distinguish between tiny bumps on the ground from larger features with some geometric shape, such as a rectangular mound\n",
    ">><br>But it takes archaeological expertise to tell whether this rectangular mound is of archaeological value\n",
    ">><br>In short: if a human can tell a feature is not useful, it very likely is not\n",
    ">><br>But if a human can tell a feature is useful, it takes an archaeology expert to know this feature has actual archaeology value\n",
    ">\n",
    ">We discussed ways to improve our current geometry-based methods:\n",
    ">1. Professor Ju suggests I can identify 'strong features.' \n",
    ">>When we value the k value in feature line extraction, some features disappear, but some stay through a range of k values\n",
    ">>Features lines of 'strong features' fall into the latter category\n",
    ">>I can extract feature lines at different values of k, and visualize the 'strength' of different features\n",
    ">\n",
    ">We compared the feature line output against the radar image (see Comparison_230330.ipynb)\n",
    ">>We found that features visible on the LiDAR scan (as indicated by feature lines) correspond to their indication on the radar datar\n",
    ">><br>However, we need better geographical alignment of the radar data and the LiDAR scan\n",
    "2. Tested CrestCODE on even smaller patch (<50k vertices)\n",
    ">The algorithm took forever to run\n",
    "><br>I will try again (leave computer running for a few hours) to see if I get any output\n",
    ">>It's possible that lack of optimization is to blame\n",
    ">><br>When I compile the code with 'make,' warnings indicate that some compilation levels are not supported (CrestCODE_warnings.ipynb)\n",
    "3. Documented compilation warnings for CrestCODE\n",
    ">File: CrestCODE_Warnings.ipynb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday April 6, 2023\n",
    "Did:\n",
    "1. Worked on alternate representation of feature lines\n",
    ">File: AnalysisPackage_v1.ipynb\n",
    "><br>Worked on modifying functions to pick out triangles associated with feature lines\n",
    "2. Studied the CrestCODE paper http://www2.riken.jp/brict/Yoshizawa/Papers/spm05ybs.pdf\n",
    ">I figured out how CrestCODE generates feature lines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday April 10, 2023\n",
    "Did: (TLDR: colored crestline triangles by frequency)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thursday April 13, 2023\n",
    "Did: (TLDR: working on coloring crestline triangles by color)\n",
    "k=10 taking 1hr+ to run! (and it's on tiny tiny patch!)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friday July 07, 2023\n",
    "Did:\n",
    "1. learnt and tested libigl's implementation of ARAP on the now fixed mesh\n",
    "- libigl's ARAP runs about 1 second faster than open3d's, but the result is indistinguishable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sunday July 09, 2023\n",
    "Did:\n",
    "1. completed project write-up (Jason_Update_230709.ipynb)\n",
    "- explained workflow used in step-by-step instruction\n",
    "- documented test results for region covering all archaeological features\n",
    "- supplied image comparison for before and after the workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday July 11, 2023\n",
    "Did:\n",
    "1. Improved illustration for before-and-after contrast in project write-up (Jason_Update_230709.ipynb)\n",
    "- used purple for 2d features and green for 3d features to better contrast with the red-and-black radar reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# July 11, 2023\n",
    "Action items:\n",
    "1. run 3d features, better details (TBK)\n",
    "2. compare against human tracing (analytical statistics, ask Tao)\n",
    "3. maybe warp if something is super-off (small degree of warp ok e.g. feature does not exactly fall on black lines in radar) (analytical statistics?)\n",
    "4. for 2, 3, get accuracy e.g. 90% match between feature and radar\n",
    "5. run 3d features on TGB central mount\n",
    "6. if 5 results are good, run 3d features on all TGB mounds"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
